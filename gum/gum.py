#  GUM: GAMBIT Universal Model Machine
#  ************************************
#  \file
#
#  Main GUM script
#
#  *************************************
#
#  \author Sanjay Bloor
#          (sanjay.bloor12@imperial.ac.uk)
#  \date 2018, 2019, 2020...
#
#  \author Tomas Gonzalo
#          (tomas.gonzalo@monash.edu)
#  \date 2019, 2020
#
#  **************************************

from __future__ import print_function

import sys
import platform
import os
import argparse
import numpy as np
from src import *
from collections import defaultdict
from distutils.dir_util import copy_tree

print()
print(banner())
print("-- Running GUM with python version", platform.python_version(), "--")
print()

parser = argparse.ArgumentParser(description="From Lagrangian to scans: GUM "
                                             "(GAMBIT Universal Models)")

# Optional command-line arguments
parser.add_argument('-f', '--file', type=str,
                      help="Specify input .GUM file.")
parser.add_argument("-d", "--dryrun", action='store_true',
                    help="GUM will perform a dry run, not saving any output.")
parser.add_argument("-r", "--reset", type=str,
                    help=("GUM will reset GAMBIT back to a previous version, "
                         "given an input .mug file generated by GUM."))
parser.add_argument('--usecache', action='store_true')
parser.set_defaults(usecache=False)

# Retrieve command-line arguments
args = parser.parse_args()

# Don't let the user create and reset at the same time
if args.file and args.reset:
    raise GumError(("\n\n\tYou may use only one of the "
                    "--file or --reset flags at any one time!"))

if args.reset and args.dryrun:
    raise GumError(("\n\n\tYou have requested a dryrun and a reset together:"
                    " this is not supported."))

# Input option: .gum file
if args.file:

    if args.dryrun:
        print("**********************************************************")
        print("GUM called with a dry run -- will not be writing to files!")
        print("**********************************************************")

    try:
        # Parse the .gum file
        inputs = check_gum_file(args.file)
        gum, output_opts = fill_gum_object(inputs)

        # decide if we need flavorkit
        spheno_options = {}
        if 'spheno' in output_opts.options.keys():
            spheno_options = output_opts.options['spheno']
            spheno_options["IncludeFlavorKit"] = False
            if "GetWilsonCoefficients" in spheno_options:
                if spheno_options["GetWilsonCoefficients"]:
                    spheno_options["IncludeFlavorKit"] = True
            if "GetFlavorObservables" in spheno_options:
                if spheno_options["GetFlavorObservables"]:
                    spheno_options["IncludeFlavorKit"] = True
            if "GetElectroweakObservables" in spheno_options:
                if spheno_options["GetElectroweakObservables"]:
                    spheno_options["IncludeFlavorKit"] = True

        # SARAH removes hyphens and underscores for .f90 files...
        clean_model_name = gum.name.replace('-','').replace('_','')

        # Create the output directory for all generated files for this model
        output_dir = os.path.join(os.getcwd(),"Outputs", gum.name)
        mkdir_if_absent(output_dir)

        # Check for a DM candidate
        if gum.dm_pdg:
            darkbit = True
        else:
            darkbit = False
            print(("No DM candidate requested -- no DarkBit routines will "
                   "be written.\n"))

        # Check whether we need to generate DecayBit output or not
        # N.B. if we don't something is quiiiiite likely to go wrong
        if output_opts.ch or output_opts.spheno:
            decaybit = True
        else:
            decaybit = False

        # Check whether we need to generate new ColliderBit code or not
        # Also check whether the correct YAML entries are filled
        if output_opts.pythia:
            colliderbit = True
            if not 'pythia' in output_opts.options:
                raise GumError(("\n\nPythia output requested but no "
                                "collider_processes specified.\n"
                                "Please amend your .gum file!"))
            collider_processes = output_opts.options['pythia'].get('collider_processes')
            if collider_processes == None:
                raise GumError(("\n\nPythia output requested but no "
                                "collider_processes specified.\n"
                                "Please amend your .gum file!"))
        else:
            colliderbit = False

        # Check to see if any of the proposed new files will
        # clash with any existing files.
        # for either the model name or clean model name
        check_for_existing_entries(gum.name, darkbit, colliderbit, output_opts)
        check_for_existing_entries(clean_model_name, darkbit, colliderbit, output_opts)

        """
        FEYNRULES/SARAH
        """

        if gum.math == 'feynrules':

            # Let GUM do a quick and dirty parse of the file first, before we
            # fire up a Mathematica kernel
            parse_feynrules_model_file(gum.mathname, gum.base_model,
                                       output_opts)

            from lib.libfr import *

            # Create the output directory for all generated FeynRules files
            mkdir_if_absent(output_dir + "/FeynRules")

            options = FROptions("feynrules", gum.mathname, gum.base_model,
                                gum.restriction, gum.LTot)
            partlist = FRVectorOfParticles()
            paramlist = FRVectorOfParameters()
            outputs = FROutputs()
            backends = FRBackends()
            backends.extend(x for x in output_opts.bes())
            mixings = {}
            err = FRError()

            # Hit it
            all_feynrules(options, partlist, paramlist, outputs, backends, err)

            if err.is_error():
                raise GumError( err.what() )

            # Get a list of all non-SM particles
            fr_bsm = [x for x in partlist if x.SM() is False]

            # Make all BSM particles work with GUM's native Particle class.
            # Find out if the spectrum needs a dependency on StandardModel_Higgs
            bsm_particle_list, add_higgs = fr_part_to_gum_part(fr_bsm)

        elif gum.math == 'sarah':

            # Let GUM do a quick and dirty parse of the file first, before we
            # fire up a Mathematica kernel, and get the model name used by sarah
            sarah_model_name = parse_sarah_model_file(gum.mathname, output_opts)


            # NOTE: code below updated so that sarah outputs recalculated
            # only when --usecache option is not set

            # Create the output directory for all generated SARAH files
            mkdir_if_absent(output_dir + "/SARAH")

            # INPUTS
            sarah_inputs = TheInputs("sarah_"+clean_model_name)
            sarah_inputs.mathname = gum.mathname
            sarah_inputs.output_opts = output_opts

            # FUNCTION
            def calc_sarah_outputs(inputs):

                import lib.libsarah as sarah

                partlist = sarah.SARAHVectorOfParticles()
                paramlist = sarah.SARAHVectorOfParameters()
                outputs = sarah.SARAHOutputs()
                backends = sarah.SARAHBackends()
                flags = sarah.SARAHMapStrBool()
                mixings = sarah.SARAHMapStrStr()
                bcs = sarah.SARAHMapStrStr()
                sphenodeps = sarah.SARAHVectorOfParameters()
                err = sarah.SARAHError()
                options = sarah.SARAHOptions("sarah", inputs.mathname)
                options.setOptions(**inputs.output_opts.options)
                backends.extend(x for x in inputs.output_opts.bes())

                # Hit it
                sarah.all_sarah(options, partlist, paramlist, outputs, backends, flags,
                        mixings, bcs, sphenodeps, err)
                
                if err.is_error():
                    raise GumError( err.what() )

                # OUTPUTS
                coutputs = TheOutputs(inputs.name)
                coutputs.partlist = decode_SARAH_partlist(partlist)
                coutputs.paramlist = decode_SARAH_paramlist(paramlist)
                coutputs.outputs = docode_SARAHOutputs(outputs)
                coutputs.flags = decode_SARAHMapStrBool(flags)
                coutputs.bcs = decode_SARAHMapStrStr(bcs)
                coutputs.mixings = decode_SARAHMapStrStr(mixings)
                coutputs.sphenodeps = decode_SARAH_paramlist(sphenodeps)
                return coutputs

            force_recalc = not args.usecache

            # get outputs
            (sarah_outputs, input_unchanged, cache_used) = load_or_calc(sarah_inputs, calc_sarah_outputs, force_recalc, 1*1024*1024*1024)

            partlist = sarah_outputs.partlist
            paramlist = sarah_outputs.paramlist
            outputs = sarah_outputs.outputs
            flags = sarah_outputs.flags
            mixings = sarah_outputs.mixings
            bcs = sarah_outputs.bcs
            sphenodeps = sarah_outputs.sphenodeps

            print('\n~~~ SARAH PARTICLES ~~~')
            members = ['pdg','name','alt_name','antiname','SC','SM','chargeX3','color','mass','alt_mass','spinX2','tree_mass']
            print(' '.join([m.center(8) for m in members]))
            for p in partlist:
                print(' '.join([str(getattr(p,'_'+m)).center(8) for m in members]))
            
            print('\n\n~~~ SARAH PARAMETERS ~~~')
            members = ['name','block','index','alt_name','bcs','shape','is_output','is_real','defvalue']
            print(' '.join([m.center(10) for m in members]))
            for p in paramlist:
                print(' '.join([str(getattr(p,'_'+m)).center(10) for m in members]))

            # Make all SM and BSM particles work with GUM's native Particle class.
            sm_particle_list, bsm_particle_list, add_higgs = sarah_part_to_gum_part(partlist)
        

        print("Finished extracting parameters from " + gum.math + ".")

        # Check to see if the DM particle exists in the model file.
        # First, initialise DM particle from particle list
        if darkbit:
            dm_set = False
            for i in range(len(partlist)):
                part = partlist[i]
                # If specified, initialise the DM candidate
                if part.pdg() == gum.dm_pdg:
                    dm = Particle(part.name(), part.antiname(),
                                  part.spinX2(), part.pdg(),
                                  part.mass(), part.chargeX3(), part.color())
                    dm_set = True

            # If we haven't found the DM candidate in the particle list,
            # throw an error
            if not dm_set:
                raise GumError(("\n\nThe WIMP candidate specified has not been "
                                "found in the {0} file. Please check your .gum "
                                "file and {0} file are consistent.\n"
                                "PDG code given = {1}"
                                ).format(gum.math, gum.dm_pdg))

            # If the user has requested MicrOMEGAs output and the DM candidate
            # does not begin with a tilde, then complain (and its anti-p.)
            # if output_opts.mo:
            #     if not dm.name.startswith('~'):
            #         raise GumError(("You have requested MicrOMEGAs output, but "
            #                         " your DM candidate has to begin with a '~'"
            #                         " for MicrOMEGAs to recognise it as an odd "
            #                         "particle.\n Please change the DM name in "
            #                         "your {} file!"
            #                         ).format(gum.math))
            #     if not dm.antiname.startswith('~'):
            #         raise GumError(("You have requested MicrOMEGAs output, but "
            #                         " your DM candidate's antiparticle also has"
            #                         " to begin with a '~' for MicrOMEGAs to "
            #                         "recognise it as an odd particle.\n "
            #                         "Note that the default behaviour will be "
            #                         "to just add a tilde at the end, and strip "
            #                         "any leading tilde, so add a line like:\n"
            #                         "\t    AntiParticleName -> \"~Chi\"\n "
            #                         "to your {} file!"
            #                         ).format(gum.math))

        """
        UFO2MDL

        If we have both UFO and MDL files, run the files through ufo2mdl to
        compare outputs. This will, e.g., add 4-fermion interactions to CalcHEP
        where FeynRules fails to do so.
        """
        # if output_opts.ch and output_opts.ufo:
        #     print("Calling UFO2MDL.")
        #     blockPrint()  # Stop the UFO2MDL output - there's lots of it
        #     ch_location = compare_mg_and_ch(outputs.get_mg(), outputs.get_ch())
        #     enablePrint() # Bring it back.
        #     if ch_location != outputs.get_ch():
        #         print("Updating location of CalcHEP files in GUM...")
        #         outputs.set_ch(ch_location)

        # Move MadGraph files from SARAH/FeynRules to contrib/MadGraph/models
        # TODO make this go to the Outputs dir instead, then ln -s from there
        # to MadGraph later.
        if output_opts.ufo:
            copy_madgraph_files(outputs.get_mg(), gum.name)

        # Clean up calchep files from SARAH/FeynRules, then copy them to the output dir
        if output_opts.ch or output_opts.mo:
            clean_calchep_model_files(outputs.get_ch(), gum.name, output_dir)

        """
        MADGRAPH -- Pythia inside here (and MadDM in the future)
        """
        if output_opts.ufo:

            # Pythia
            if output_opts.pythia:

                collider_processes = output_opts.options['pythia'].get('collider_processes')
                multiparticles = output_opts.options['pythia'].get('multiparticles')
                if collider_processes is not None:
                    # Link MadGraph files output by SARAH/FeynRules to
                    # MadGraph's contrib/MadGraph/models
                    # still TODO

                    # Create the output directory for all generated MadGraph
                    # files
                    mg5_output_dir = output_dir + "/MadGraph5_aMC"
                    mkdir_if_absent(mg5_output_dir)

                    # Clear and remake the copy of Pythia that will receive the
                    #  matrix element code produced by MadGraph
                    pristine_pythia_dir = os.path.join(os.getcwd(),
                                                       'contrib','Pythia')
                    new_pythia_dir = mg5_output_dir + "/Pythia_patched"
                    remove_tree_quietly(new_pythia_dir)

                    copy_tree(pristine_pythia_dir, new_pythia_dir)

                    # Create the MadGraph script
                    # TODO determine all possible BSM processes automatically
                    # when collider_processes is missing from the .gum file
                    mg5_dir = os.path.join(os.getcwd(),'contrib','MadGraph')
                    make_madgraph_script(mg5_dir, mg5_output_dir, gum.name,
                                         collider_processes,
                                         multiparticles)

                    # Add MadGraph to path and import the python interface
                    sys.path.append(mg5_dir)
                    import madgraph.interface.master_interface as mi

                    # Run MadGraph
                    call_madgraph(mg5_dir, mg5_output_dir, mi)

                else:
                    raise GumError(("Pythia output requested but no "
                                    "collider_processes specified.\n"
                                    "Please amend your .gum file!"))

        print("")
        print("Finished running external codes...")
        print("Now attempting to write proposed GAMBIT code.")

        # Create defaultdict for reset file.
        reset_contents = defaultdict(lambda: defaultdict(list))

        # Dictionaries with capability and model definitions to add to the list
        capability_definitions = {}
        model_definitions = {}

        """
        REGISTRATION OF NEW PARTICLES
        """

        # Need to know how GAMBIT refers to each particle. Scrape information
        # from particle_database.yaml.
        gambit_pdgs, decaybit_dict = get_gambit_particle_pdg_dict()

        # Check every new particle is in the database
        missing_parts = check_all_particles_present(partlist, gambit_pdgs)

        if len(missing_parts) != 0:
           # Add new particles to the database, refresh the dicts
           gambit_pdgs, decaybit_dict, particleDB = \
               add_new_particleDB_entry(missing_parts, gum.dm_pdg,
                                        gambit_pdgs, decaybit_dict,
                                        reset_contents, gum.name,
                                        gum.dm_decays)

        # Grab the antiparticles
        antiparticle_dict = get_antiparticles(partlist)

        # Return a list of the PDG codes of all Higgses involved
        higgses, neutral_higgses, charged_higgses = \
            get_higgses(bsm_particle_list)

        """
        PARAMETERS
        """

        # Initialise all of the model parameters, for writing spectra,
        # model files - remove all SM stuff from parameter list.
        if gum.math == "feynrules":
            parameters = fr_params(paramlist, add_higgs)
        else:
            parameters = sarah_params(paramlist, mixings, add_higgs,
                                      gambit_pdgs, partlist, bcs)

        # Get the parameters sorted by block
        blockparams = sort_params_by_block(parameters, mixings)
        # Dict of which parameters are real.
        reality_dict = parameter_reality_dict(parameters)


        """
        MODELS
        """

        print("Adding new model {0} to GAMBIT.".format(gum.name))

        # For FeynRules, use masses of particles as input parameters
        if gum.math == 'feynrules':
            # Add all of the masses of BSM particles as pole masses.
            # Also removes all duplicate entries that can arise
            # for e.g. multiplets with same tree-level masses
            parameters = add_masses_to_params(parameters, bsm_particle_list,
                                              gambit_pdgs, add_higgs)

        # Get the model parameters out of the parameter list
        model_parameters = get_model_parameters(parameters, add_higgs)

        model_header = add_to_model_hierarchy(gum.spec, gum.name,
                                              model_parameters, model_definitions,
                                              capability_definitions)

        # Get the spectrum parameters out of the parameter list
        spectrum_parameters = get_spectrum_parameters(parameters, blockparams,
                                                      bsm_particle_list,
                                                      partlist, gambit_pdgs,
                                                      output_opts.spheno)

        subspec_wrapper = write_subspectrum_wrapper(gum.name,
                                                    spectrum_parameters)
        spec_contents = write_spectrumcontents(gum.name, spectrum_parameters)
        reg_spec, reg_spec_num = add_to_registered_spectra(gum.name)


        # print('\n~~~ GUM BSM PARTICLES ~~~')
        # members = ['PDG_code','name','alt_name','antiname','own_conjugate','chargeX3','color','mass','alt_mass_name','spinX2','tree_mass','conjugate_PDG_code']
        # print(' '.join([m.center(8) for m in members]))
        # for p in bsm_particle_list:
        #     print(' '.join([str(getattr(p,m)).center(8) for m in members]))

        # print('\n~~~ GUM SM PARTICLES ~~~')
        # members = ['PDG_code','name','alt_name','antiname','own_conjugate','chargeX3','color','mass','alt_mass_name','spinX2','tree_mass','conjugate_PDG_code']
        # print(' '.join([m.center(8) for m in members]))
        # for p in sm_particle_list:
        #     print(' '.join([str(getattr(p,m)).center(8) for m in members]))

        # print('\n\n~~~ GUM PARAMETERS ~~~')
        # members = ['name','block','index','alt_name','bcs','shape','is_output','is_real','default','fullname','gb_in','fullparticlename','tag','sm']
        # print(' '.join([m.center(10) for m in members]))
        # for p in parameters:
        #     print(' '.join([str(getattr(p,m)).center(10) for m in members]))

        """
        SPHENO
        """

        # Forward declare some variables
        decays = {}
        spheno_decays = {}

        if output_opts.spheno:

            # Move SPheno files from SARAH to Outputs.
            copy_spheno_files_output(clean_model_name, output_dir, SPHENO_DIR,
                              outputs.get_sph())

            # Pristine and patched SPhenos
            pristine_spheno_dir = output_dir + "/SPheno"
            patched_spheno_dir = output_dir + "/SPheno_patched"

            # Patch the files
            print("Patching SPheno...")

            patch_spheno(clean_model_name, sarah_model_name, patched_spheno_dir,
                         flags, bsm_particle_list, spheno_options)

            fullpath = "Backends/patches/sarah-spheno/{0}/{1}".format(SPHENO_VERSION,
                                                               gum.name)
            fullfile = "patch_sarah-spheno_"+SPHENO_VERSION+"_"+gum.name
            
            # Create a diff vs. the out of the [SARAH]box
            write_backend_patch(output_dir, pristine_spheno_dir,
                                patched_spheno_dir,
                                "sarah-spheno",
                                SPHENO_VERSION,
                                fullpath = fullpath,
                                fullfile = fullfile)


            # Get the defs of any SPheno dependencies
            deps = spheno_dependencies(sphenodeps)

            # Write frontends for SPheno. That's a lotta scrapin'.
            print("Writing SPheno frontends.")
            spheno_src, spheno_header, backend_types, btnum = \
                write_spheno_frontends(clean_model_name, sarah_model_name, parameters,
                                       sm_particle_list, bsm_particle_list, flags,
                                       patched_spheno_dir, output_dir,
                                       blockparams, gambit_pdgs, mixings,
                                       reality_dict, deps, bcs,
                                       charged_higgses, neutral_higgses,
                                       gum.name, spheno_options, capability_definitions)

            # cmake entry
            spheno_cmake = write_spheno_cmake_entry(gum.name, SPHENO_VERSION,
                                                    clean_model_name)

            print("Writing SPheno decay table.")
            spheno_decay_tables, spheno_decays = \
                make_spheno_decay_tables(patched_spheno_dir, clean_model_name, sarah_model_name)

            # DecayBit entry
            print("Writing SPheno module functions for DecayBit.")
            spheno_decay_src, spheno_decay_header = \
                write_spheno_decay_entry(gum.name, clean_model_name)

            # HiggsCouplingsTable
            hct_src, hct_head, hb_pattern = new_hct_switch(gum.name, gum.spec,
                                                           neutral_higgses,
                                                           gambit_pdgs,
                                                           len(higgses))

            # Save this dictionary as the global 'decays' for other backends
            decays = spheno_decays

        """
        CALCHEP
        """

        # generic CalcHEP model file -> python list of lists converter
        def parse_calchep_model_file(file_path):
            with open(file_path, 'r') as f:
                # grab everything
                contents = f.read() 
                # delete whitespace
                contents = re.sub(r'[ \t]', '', contents) 
                # split file into lines
                lines = contents.splitlines()
                # if less <= 3 lines then throw error
                if len(lines) <= 3:
                    raise GumError('calchep model file: "{0}" does not contain any info'.format(file_path))
                # discard first 3 garbage lines
                lines = lines[3:]
                # skip lines starting with === (todo:figure out what this actually is)
                lines = [l for l in lines if not l.startswith('===')]
                # separate lines into individual elements
                return [line.split('|') for line in lines]

        # structures to represent calchep model files
        class Calchep_particle:
            def __init__(self, elements):
                if len(elements) != 11:
                    raise GumError('wrong number of elements for calchep_particle')
                self.name_full = elements[0] # more descriptive name
                self.name_short = elements[1] # short name limited to 7 characters (calhep uses this one)
                self.name_anti = elements[2] # name of corresponding antiparticle (also short)
                self.pdg_code = elements[3] # pdg number
                self.spinX2 = elements[4] # spin times 2
                self.mass = elements[5] # mass
                self.width = elements[6] # decay width
                self.color = elements[7] # color representation
                self.aux = elements[8] # ???
                self.latex = elements[9] # latex code for particle name
                self.latex_anti = elements[10] # latex code for antiparticle name

        class Calchep_independent_param:
            def __init__(self, elements):
                # add empty comment if missing (although this might be a gum bug
                # since gum adds these. Should probably check)
                if len(elements) == 2:
                    elements.append('')
                if len(elements) != 3:
                    raise GumError('wrong number of elements for calchep_independent_param')
                self.name_short = elements[0] # parameter name (limited to 7 characters)
                self.value = elements[1] # parameter value
                self.comment = elements[2] # a comment

        class Calchep_dependent_param:
            def __init__(self, elements):
                if len(elements) != 2:
                    raise GumError('wrong number of elements for calchep_dependent_param')
                self.name_short = elements[0] # parameter name (limited to 7 characters)
                self.expression = elements[1] # mathematical expression to calculate it

        class Calchep_vertex:
            def __init__(self, elements):
                if len(elements) != 6:
                    raise GumError('wrong number of elements for calchep_vertex')
                # names of vertex particles
                self.part_names = [x for x in elements[0:3] if x != '']
                self.factor = elements[4] # vertex factor
                self.lorentz_part = elements[5] # lorentz part

        # parse the calchep model files into lists
        # TODO: check FeynRules model names (maybe some are different?)

        ch_particles = parse_calchep_model_file(outputs.get_ch() + '/prtcls1.mdl')
        ch_independent_params = parse_calchep_model_file(outputs.get_ch() + '/vars1.mdl')
        ch_dependent_params = parse_calchep_model_file(outputs.get_ch() + '/func1.mdl')
        ch_vertices = parse_calchep_model_file(outputs.get_ch() + '/lgrng1.mdl')

        # finally parse the list of lists into list of classes

        # TODO: turn these into dicts indexed by PDG numbers
        # TODO: add PDGs for particle names

        ch_particles = [Calchep_particle(x) for x in ch_particles]
        ch_independent_params = [Calchep_independent_param(x) for x in ch_independent_params]
        ch_dependent_params = [Calchep_dependent_param(x) for x in ch_dependent_params]
        ch_vertices = [Calchep_vertex(x) for x in ch_vertices]

        print('\n~~~ CALCHEP PARTICLES ~~~')
        members = ['name_full','name_short','name_anti','pdg_code','spinX2','mass','width','color','aux','latex','latex_anti']
        print(' '.join([m.center(8) for m in members]))
        for p in ch_particles:
            print(' '.join([str(getattr(p,m)).center(8) for m in members]))

        print('\n\n~~~ CALCHEP PARAMETERS ~~~')
        members = ['name_short','value','comment']
        print(' '.join([m.center(10) for m in members]))
        for p in ch_independent_params:
            print(' '.join([str(getattr(p,m)).center(10) for m in members]))

        # Obtain all model interactions from CalcHEP model files.
        # Also grab the PDG codes of each particle and the names of their
        # masses -- we'll want to use this for writing the micromegas frontend
        calchep_pdg_codes = {}
        if output_opts.ch or output_opts.mo:

            (interactions, calchep_pdg_codes, calchep_masses,
            calchep_widths, aux_particles) = get_vertices(outputs.get_ch())

        if output_opts.ch:

            # Save a dictionary of all processes that GAMBIT may write matrix
            # element code for in CalcHEP
            ch_processes = defaultdict(lambda: defaultdict(list))

            # Obtain all 3-point vertices that are BSM.
            three_pi_bsm = [i.particles for i in interactions
                            if i.num_particles() == 3 and i.is_sm() == False]

            three_body_decays = decay_sorter(three_pi_bsm, aux_particles,
                                             antiparticle_dict)

            # If SPheno hasn't been run then save the tree-level decays from CH
            # to the global 'decays' variable
            if not bool(decays):
                decays = ch_decays_to_dict(three_body_decays)


            print("Writing CalcHEP module functions for DecayBit")
            # CalcHEP specific decays
            decaybit_src_ch = ""

            """
            DECAYBIT
            """
            # TODO: if we have SPheno output, do we /really/ want
            # to provide CalcHEP DecayBit entries too?

            # Pass all interactions by first PDG code needed.
            for i in range(len(three_body_decays)):
                decaybit_src_ch += write_decaytable_entry_calchep(
                                                          three_body_decays[i],
                                                          gum.name,
                                                          calchep_pdg_codes,
                                                          gambit_pdgs,
                                                          decaybit_dict,
                                                          ch_processes)

            decay_roll, new_decays = \
                write_decaybit_rollcall_entry_calchep(gum.name, gum.spec,
                                                      three_body_decays,
                                                      decaybit_dict,
                                                      gambit_pdgs,
                                                      capability_definitions)

            all_decays_src, all_decays_header = \
                amend_all_decays_calchep(gum.name, gum.spec, new_decays)

        """
        COLLIDERBIT
        """
        if colliderbit:

            print("Writing new module functions for ColliderBit")

            # Create the output directory for all generated ColliderBit sources
            cb_output_dir = output_dir + "/ColliderBit"
            mkdir_if_absent(cb_output_dir)

            # Write ColliderBit headers and sources for the new model
            new_colliderbit_model(cb_output_dir, gum.name)

        """
        DARKBIT
        """

        if darkbit:

            # Set the following variables to None for now - if they're not None,
            # they need to be computed and passed to the writing routines.
            pc = None            # Do we write the Process Catalogue?
            sv = None            # Do we figure out cross-sections?
            products = None      # What are the products of DM ann./decay?
            propagators = None   # Any propagators involved?

            # If we have decaying DM, we can write the PC with any DecayTable.
            if gum.dm_decays == True:
                pc = True

            print("Writing new module functions for DarkBit")

            # Conditional on CalcHEP files being made.
            if output_opts.ch:

                # Definitely write process catalogue output
                pc = True

                # If DM doesn't decay (i.e. it annihilates), then
                # we want to use the sv (= 'sigma*v') routines.
                if gum.dm_decays == False:
                    sv = True

                    # Obtain all three-field vertices
                    three_f = [i.particles for i in interactions
                               if i.num_particles() == 3]
                    # And all 4-point BSM vertices
                    four_f = [i.particles for i in interactions
                             if i.num_particles() == 4 and i.is_sm() == False]

                    # Get all annihilation products and propagators involved in
                    # DM + DM -> X + Y at tree-level
                    products, propagators = \
                        sort_annihilations(dm, three_f, four_f, aux_particles,
                                           antiparticle_dict)

                # Otherwise - products are the decays of the DM particle.
                else:
                    products = decays[gum.dm_pdg]

            # If micrOMEGAs requested
            if output_opts.mo:

                print("Writing micrOMEGAs interface for DarkBit.")

                mo_src = write_micromegas_src(gum.name, gum.spec, gum.math,
                                              parameters, bsm_particle_list,
                                              gambit_pdgs, calchep_masses,
                                              calchep_widths, ch_particles, ch_independent_params, ch_dependent_params, ch_vertices)
                mo_head = write_micromegas_header(gum.name, gum.math,
                                                  parameters, capability_definitions, ch_particles, ch_independent_params, ch_dependent_params, ch_vertices)

            darkbit_src = write_darkbit_src(dm, pc, sv, products,
                                            propagators, gum.dm_decays,
                                            gambit_pdgs, gum.name,
                                            calchep_pdg_codes,
                                            bsm_particle_list, higgses,
                                            ch_processes)

            pc_cap, dmid_cap, dmconj_cap = write_darkbit_rollcall(gum.name, pc,
                                                                  gum.dm_decays)

            wimp_prop_h, wimp_prop_c = write_wimp_props(gum.name)

        """
        CALCHEP SRC
        Must be done after DecayBit & DarkBit as we want the matrix elements.
        """

        if output_opts.ch:
            # Entries for header file
            ch_src_sl, ch_src_pl, ch_head = add_calchep_switch(gum.name,
                                                               gum.spec,
                                                               ch_processes, gum.math, parameters, bsm_particle_list,
                                              gambit_pdgs, calchep_masses,
                                              calchep_widths, ch_particles, ch_independent_params, ch_dependent_params, ch_vertices)

        """
        SPECBIT
        """

        print("Writing basic container SpecBit interface...")
        spectrum_src, higgsdefined = write_spectrum(gum.name, parameters,
                                                    gum.spec, add_higgs,
                                                    output_opts.spheno,
                                                    gambit_pdgs,
                                                    neutral_higgses,
                                                    charged_higgses,
                                                    blockparams,
                                                    bsm_particle_list,
                                                    spheno_decays, partlist)
        # If the Higgs has now been defined by some other parameters,
        # don't need to have mH as a model param.
        if higgsdefined: add_higgs = False

        spectrum_header = write_spectrum_header(gum.name, add_higgs,
                                                output_opts.spheno, higgses,
                                                capability_definitions)
        spec_rollcall = write_specbit_rollcall(gum.name)

        """
        VEVACIOUS
        """

        if output_opts.vev:
            vev_src = write_vevacious_src(gum.name, outputs.get_vev(), gum.spec,
                                          blockparams)

        """
        PYTHIA
        """

        # Have we created a new Pythia backend?
        if output_opts.pythia:
            print(("Patching Pythia to inject new matrix elements into its "
                   "Process Container and shared library."))
            pythia_groups = output_opts.options['pythia'].get('pythia_groups')
            fix_pythia_lib(gum.name, new_pythia_dir, pythia_groups,
                           bsm_particle_list, decays)
            print("Creating a diff vs original version of Pythia.")
            write_backend_patch(output_dir, pristine_pythia_dir, new_pythia_dir,
                                "pythia_"+gum.name.lower(),
                                "8."+base_pythia_version)
            print("Writing an additional patch for the new version of Pythia.")
            patch_pythia_patch(parameters, gum.name, reset_contents)
            print("Creating a cmake entry for Pythia"+gum.name+".")
            pythia_cmake = write_pythia_cmake_entry(gum.name, output_dir)
            print(("Setting the default version of Pythia_"+gum.name+" for "
                   "BOSSed classes to 8."+base_pythia_version))
            write_pythia_capability_defs(gum.name, capability_definitions)

            # Adding in a UserHook
            print("Writing a Pythia UserHooks class for ColliderBit")
            set_userhook = write_set_userhook(gum.name,base_pythia_version)
            apply_userhook = write_apply_userhook(gum.name)


        # Stop now if we're just doing a dry run
        if args.dryrun:
            print("")
            print("Dry run finished.")
            print("")
            exit()

        #################################################################
        ################### DRY RUN STOPS HERE ##########################
        # All file writing routines HERE, once everything has gone okay.#
        #################################################################

        print("")
        print("Now putting the new code into GAMBIT.")

        # ParticleDB
        if len(missing_parts) :
            write_particleDB(particleDB)

        # Models
        m = "Models"
        write_file("models/" + gum.name + ".hpp", m, model_header,
                   reset_contents)
        write_file("SpectrumContents/" + gum.name + ".cpp", m, spec_contents,
                   reset_contents)
        write_file("SimpleSpectra/" + gum.name + "SimpleSpec" + ".hpp", m,
                    subspec_wrapper, reset_contents)
        amend_file("SpectrumContents/RegisteredSpectra.hpp", m, reg_spec,
                    reg_spec_num, reset_contents)


        # SpecBit
        m = "SpecBit"
        write_file("SpecBit_" + gum.name + ".cpp", m, spectrum_src,
                   reset_contents)
        write_file("SpecBit_" + gum.name + "_rollcall.hpp", m, spectrum_header,
                    reset_contents)
        num = find_string("SpecBit_rollcall.hpp", m,
                          "SpecBit_tests_rollcall.hpp")[1]
        amend_file("SpecBit_rollcall.hpp", m, spec_rollcall, num,
                   reset_contents)

        # DecayBit
        if decaybit:
            m = "DecayBit"
            # Append to the end of DecayBit -- just before all_decays
            num = find_string("DecayBit.cpp", m, "void all_decays")[1]
            if output_opts.ch:
                amend_file("DecayBit.cpp", m, decaybit_src_ch, num-3,
                           reset_contents)
                for i in range(len(decay_roll)):
                    if find_capability(decay_roll[i][0], m)[0]:
                        amend_rollcall(decay_roll[i][0], m, decay_roll[i][1],
                                       reset_contents)
                    elif find_quick_function(decay_roll[i][0],m)[0]:
                        amend_rollcall(decay_roll[i][0], m , decay_roll[i][1],
                                       reset_contents)
                    else:
                        num = find_string("DecayBit_rollcall.hpp", m,
                                          "#define CAPABILITY decay_rates")[1]
                        amend_file("DecayBit_rollcall.hpp", m, decay_roll[i][1],
                                   num-2, reset_contents)
                if len(new_decays) > 0:
                    num = find_string("DecayBit_rollcall.hpp", m,
                                      "MODEL_CONDITIONAL_DEPENDENCY"\
                                      "(MSSM_spectrum")[1]
                    amend_file("DecayBit_rollcall.hpp", m, all_decays_header,
                               num-1, reset_contents)
                    num = find_string("DecayBit.cpp", m, "decays(\"omega\")")[1]
                    amend_file("DecayBit.cpp", m, all_decays_src, num,
                               reset_contents)
            num = find_string("DecayBit.cpp", m, "void all_decays")[1]
            if output_opts.spheno:
                amend_file("DecayBit.cpp", m, spheno_decay_src, num-3,
                            reset_contents)
                num = find_string("DecayBit_rollcall.hpp", m,
                                  "#define CAPABILITY decay_rates")[1]
                amend_file("DecayBit_rollcall.hpp", m, spheno_decay_header,
                           num+2, reset_contents)

        # DarkBit
        if darkbit:
            m = "DarkBit"
            amend_rollcall("DarkMatter_ID", m, dmid_cap, reset_contents)
            amend_rollcall("DarkMatterConj_ID", m, dmconj_cap,
                           reset_contents)
            # Add to the wimp properties
            num = find_string("DarkBit_rollcall.hpp", m,"MODEL_CONDITIONAL_DEPENDENCY(DMEFT_spectrum, Spectrum, DMEFT)")[1]
            amend_file("DarkBit_rollcall.hpp", m, wimp_prop_h,num, reset_contents)
            
            num = find_string("DarkBit.cpp", m,"else if(ModelInUse(\"DMEFT\"))")[1]
            amend_file("DarkBit.cpp", m, wimp_prop_c,num-1, reset_contents)

            write_file(gum.name + ".cpp", m, darkbit_src, reset_contents)
            if pc:
                amend_rollcall("TH_ProcessCatalog", m, pc_cap, reset_contents)
            # If DM isn't decaying, we can use the built-in
            # relic density routines. If not: no, they won't work.
            if pc and not gum.dm_decays:
                add_new_model_to_function("DarkBit_rollcall.hpp", "DarkBit",
                                          "RD_spectrum",
                                          "RD_spectrum_from_ProcessCatalog",
                                          gum.name, reset_contents,
                                          pattern="ALLOW_MODELS")
                add_new_model_to_function("DarkBit_rollcall.hpp", "DarkBit",
                                          "RD_eff_annrate",
                                          "RD_eff_annrate_from_ProcessCatalog",
                                          gum.name, reset_contents,
                                          pattern="ALLOW_MODELS")

        # ColliderBit
        m = "ColliderBit"
        if output_opts.pythia:
            copy_file("models/"+gum.name+".hpp", m, output_dir, reset_contents,
                      existing = False)
            copy_file("models/"+gum.name+".cpp", m, output_dir, reset_contents,
                      existing = False)

            #Adding in the Set UserHooks Changes.
            num = find_string("colliders/Pythia8/SetHooksClass.hpp", m,
                                  "    class SetHooks")[1]
            amend_file("colliders/Pythia8/SetHooksClass.hpp", m, set_userhook,
                           num+14, reset_contents)

            num = find_string("getPy8Collider.hpp", m,
                                  "          catch (typename Py8Collider<PythiaT,EventT,hepmc_writerT>::InitializationError& e)")[1]
            amend_file("getPy8Collider.hpp", m, apply_userhook,
                           num+10, reset_contents)

            # write all invisible particles in the model to Event header
            num = find_string("heputils/include/HEPUtils/Particle.h", "contrib",
                                  "      if (pid() == 1000022 || pid() == 1000039) return false;")[1]
            amend_file("heputils/include/HEPUtils/Particle.h", "contrib", get_invisibles(gum.invisibles_pdg),
                           num, reset_contents)

        # HiggsBounds interface
        if output_opts.spheno:
            if len(higgses) == 1:
                num = find_string("ColliderBit_Higgs.cpp", m,
                        "ModelInUse(\"StandardModel_Higgs\")")[1]
                amend_file("ColliderBit_Higgs.cpp", m, hct_src, num-1,
                           reset_contents)
                num = find_string("ColliderBit_Higgs_rollcall.hpp", m,
                        "MODEL_CONDITIONAL_DEPENDENCY(ScalarSingletDM_Z2")[1]
                amend_file("ColliderBit_Higgs_rollcall.hpp", m, hct_head, num-1,
                           reset_contents)
            else:
                # FIXME: The Higgs couplings part of gum does not work now, fix it
                num = find_string("ColliderBit_Higgs.cpp", m,
                        "No valid model for MSSMLikeHiggs_ModelParameters.")[1]
                amend_file("ColliderBit_Higgs.cpp", m, hct_src, num-1,
                           reset_contents)
                num = find_string("ColliderBit_Higgs_rollcall.hpp", m,
                        "MODEL_CONDITIONAL_DEPENDENCY(MSSM_spectrum")[1]
                amend_file("ColliderBit_Higgs_rollcall.hpp", m, hct_head, num-1,
                           reset_contents)
            add_new_model_to_function("ColliderBit_Higgs_rollcall.hpp",
                                      m, "HB_ModelParameters_neutral",
                                      hb_pattern, gum.name, reset_contents,
                                      pattern="ALLOW_MODELS")

        # Backends
        m = "Backends"
        rebuild_backends = []

        # CalcHEP
        if output_opts.ch:
            # Move files from output to Gambit dir
            ch_patch_dir = "patches/calchep/3.6.27/Models/" + gum.name + '/'
            ch_dest_dir = "../Backends/" + ch_patch_dir
            ch_src_dir = output_dir + "/" + m + "/" + ch_patch_dir
            remove_tree_quietly(ch_dest_dir)
            mkdir_if_absent(ch_dest_dir, reset_contents)
            for ch_file in os.listdir(ch_src_dir):
                copy_file(ch_file, m, output_dir, reset_contents,
                          existing = False, overwrite_path = ch_patch_dir)
            f = "frontends/CalcHEP_3_6_27.cpp"
            num = find_string(f, m, "setModel(modeltoset, 1)")[1]
            amend_file(f, m, ch_src_sl, num-2, reset_contents)
            num = find_string(f, m, "END_BE_INI_FUNCTION")[1]
            amend_file(f, m, ch_src_pl, num-2, reset_contents)
            f = "frontends/CalcHEP_3_6_27.hpp"
            num = find_string(f, m, "backend_undefs.hpp")[1]
            amend_file(f, m, ch_head, num-2, reset_contents)
            num = find_string(f, m, "BE_FUNCTION")[1]
            amend_file(f, m, "BE_ALLOW_MODELS({0})\n".format(gum.name), num-2,
                       reset_contents)
        
        # micrOMEGAs
        if output_opts.mo:
            print("Patching micrOMEGAs...")
            # Pristine and patched micrOMEGAs
            pristine_mo_dir = output_dir + "/micrOMEGAs"
            patched_mo_dir = output_dir + "/micrOMEGAs_patched"
            # Copy micromegas files to Backend patches from the cleaned
            # CalcHEP directory
            copy_micromegas_files(gum.name, reset_contents)
            # Add the patch file to the directory too
            patch_micromegas(gum.name, reset_contents)
            # Now write the headers
            ver = "3.6.9.2"
            be = "MicrOmegas_" + gum.name
            be_loc = "micromegas/{0}/{1}/libmicromegas.so".format(ver, gum.name)
            f = "frontends/MicrOmegas_{0}_{1}".format(gum.name,
                                                      ver.replace('.','_'))
            write_file(f+".cpp", m, mo_src, reset_contents)
            write_file(f+".hpp", m, mo_head, reset_contents)
            add_to_backend_locations(be, be_loc, ver, reset_contents)
            add_micromegas_to_cmake(gum.name, reset_contents)
            add_micromegas_to_darkbit_rollcall(gum.name, reset_contents,
                                               gum.dm_decays)

        # Pythia
        if output_opts.pythia:
            be = "pythia_"+gum.name.lower()
            safe_ver = "8_"+base_pythia_version
            ver = "8."+base_pythia_version
            print("Creating BOSS config files for Pythia_"+gum.name+".")
            write_boss_configs_for_pythia(gum.name, output_dir,reset_contents)
            copy_file(be+"/"+ver+"/patch_"+be+"_"+ver+".dif", m, output_dir,
                      reset_contents, existing = False)
            add_to_backend_locations("Pythia_"+gum.name,
                                     be+"/"+ver+"/lib/libpythia8.so", ver,
                                     reset_contents)
            add_to_backends_cmake(pythia_cmake, reset_contents,
                                  string_to_find="# Nulike")
            add_to_default_bossed_version("Pythia_"+gum.name,
                                          safe_ver, reset_contents)

        # SPheno
        if output_opts.spheno:
            ver = SPHENO_VERSION
            be = "SARAHSPheno_"+gum.name
            be_loc = (
                   "sarah-spheno/{0}/{1}/lib/libSPheno{2}.so"
            ).format(ver, gum.name, clean_model_name)
            f = "frontends/SARAHSPheno_{0}_{1}".format(gum.name,
                                                       ver.replace('.','_'))
            write_file(f+".cpp", m, spheno_src, reset_contents)
            write_file(f+".hpp", m, spheno_header, reset_contents)
            add_to_backend_locations(be, be_loc, ver, reset_contents)
            add_to_backends_cmake(spheno_cmake, reset_contents,
                                  string_to_find="# gm2calc")
            # Move SPheno files to Backend/patches/...
            copy_spheno_files_gambit(gum.name, clean_model_name, ver, output_dir, reset_contents)
            patchloc = (
                     "sarah-spheno/{0}/{1}/patch_sarah-spheno_{0}_{1}.dif"
            ).format(ver, gum.name)
            mkdir_if_absent(os.path.dirname(full_filename(patchloc,m)),reset_contents)
            copy_file(patchloc, m, output_dir, reset_contents, existing = False)
            # SPheno DecayTable
            filename = (
                "data/SARAHSPheno_{0}_{1}_decays_info.dat"
            ).format(gum.name, SPHENO_VERSION.replace('.','_'))
            write_file(filename, m, spheno_decay_tables, reset_contents)
            # SPheno backend_types
            amend_file("backend_types/SPheno.hpp", m, backend_types, btnum-2,
                       reset_contents)
            # Check if backend needs rebuild
            be_install_dir  = "../Backends/installed/sarah-spheno/" + ver + "/" + gum.name
            gum_patched_dir = output_dir + '/SPheno_patched'
            check_backend_rebuild('sarah-spheno_'+gum.name, ver, be_install_dir,
                                  gum_patched_dir, rebuild_backends,
                                  file_endings=('F90','f90','Makefile'),
                                  build_dir='../build')

            if spheno_options["IncludeFlavorKit"]:

                # write flavor observables to FlavBit

                # TODO: some of these have corresponding capabilities
                # already in gambit while others are new. We should
                # probabily make a map for converting them to the
                # gambit name when possible and adding them to the 
                # capability that already exists.

                # for now just dump them in FlavBit as is

                (backend_capabilities, obs_capabilities) = get_spheno_flavbit_info(clean_model_name)

                contents = ""
                for b,f in zip(backend_capabilities, obs_capabilities):
                    tmp = "\n  #define CAPABILITY {1}\n"
                    tmp += "  START_CAPABILITY" + "\n"
                    tmp += "    #define FUNCTION SPheno_{1}\n"
                    tmp += "    START_FUNCTION(double)" + "\n"
                    tmp += "    ALLOW_MODELS({0})" + "\n"
                    tmp += "    DEPENDENCY({0}_spectrum, Spectrum)" + "\n"
                    tmp += "    BACKEND_REQ({2}, (libSPheno{0}), double, () )" + "\n"
                    tmp += "    #undef FUNCTION" + "\n"
                    tmp += "  #undef CAPABILITY" + "\n"
                    contents += tmp.format(clean_model_name, f, b)

                num = find_string("FlavBit_rollcall.hpp", "FlavBit", "START_MODULE")[1]
                amend_file("FlavBit_rollcall.hpp", "FlavBit", contents, num+1, reset_contents)


                contents = ""
                for b,f in zip(backend_capabilities, obs_capabilities):
                    tmp = "\n    void SPheno_{0}(double& result){{ result = Pipes::SPheno_{0}::BEreq::{1}(); }}\n"
                    contents += tmp.format(f,b)

                num = find_string("FlavBit.cpp", "FlavBit", "Finished SuperIso_nuisance_fill")[1]
                amend_file("FlavBit.cpp", "FlavBit", contents, num+2, reset_contents)


                # write electroweak observables to PrecisionBit

                (backend_capabilities, obs_capabilities) = get_spheno_precisionbitbit_info(clean_model_name)

                contents = ""
                for b,f in zip(backend_capabilities, obs_capabilities):
                    tmp = "\n  #define CAPABILITY {1}\n"
                    tmp += "  START_CAPABILITY" + "\n"
                    tmp += "    #define FUNCTION SPheno_{1}\n"
                    tmp += "    START_FUNCTION(double)" + "\n"
                    tmp += "    ALLOW_MODELS({0})" + "\n"
                    tmp += "    DEPENDENCY({0}_spectrum, Spectrum)" + "\n"
                    tmp += "    BACKEND_REQ({2}, (libSPheno{0}), double, () )" + "\n"
                    tmp += "    #undef FUNCTION" + "\n"
                    tmp += "  #undef CAPABILITY" + "\n"
                    contents += tmp.format(clean_model_name, f, b)

                num = find_string("PrecisionBit_rollcall.hpp", "PrecisionBit", "START_MODULE")[1]
                amend_file("PrecisionBit_rollcall.hpp", "PrecisionBit", contents, num+1, reset_contents)

                contents = "\n"
                for b,f in zip(backend_capabilities, obs_capabilities):
                    tmp = "\n    void SPheno_{0}(double& result){{ result = Pipes::SPheno_{0}::BEreq::{1}(); }}\n"
                    contents += tmp.format(f,b)

                num = find_string("PrecisionBit.cpp", "PrecisionBit", "// Module functions")[1]
                amend_file("PrecisionBit.cpp", "PrecisionBit", contents, num, reset_contents)




        # Vevacious
        if output_opts.vev:
            copy_vevacious_files(gum.name, outputs.get_vev(), reset_contents)
            num = find_string("SpecBit_VS.cpp", "SpecBit",
                              "} // end namespace SpecBit")[1]
            amend_file("SpecBit_VS.cpp", "SpecBit", vev_src, num-1,
                       reset_contents)
            write_vevacious_rollcall(gum.name, gum.spec, reset_contents)

        # Write capability and model definitions
        write_capability_definitions("capabilities.dat", gum.name, capability_definitions, reset_contents)
        write_model_definitions("models.dat", gum.name, model_definitions, reset_contents)

        # Generate a file containing all of the bib tags for the backends used.
        bibtags = generate_bib_tags(output_opts,gum.math)
        num = find_string("citation_keys.hpp", "Utils","      // GUM additions")[1]
        amend_file("citation_keys.hpp", "Utils", bibtags, num,reset_contents)

        # Write a simple YAML file.
        drop_yaml_file(gum.name, model_parameters, add_higgs, reset_contents,
                       gum.spec, output_opts.spheno, get_spheno_yaml_capabilities(clean_model_name))
        print(("\nGUM has dropped a test YAML file at "
               "$GAMBIT/yaml_files/{0}_example.yaml!").format(gum.name))

        # Inform user to rebuild backends
        if rebuild_backends:
            print(("The following backends have been changed, if you are not using "
                   "the config script provided make sure to rebuild them: "
                   "{0}").format(rebuild_backends))

        # Save output to a .mug file for resetting purposes
        mug_file = "mug_files/{0}.mug".format(gum.name)
        drop_mug_file(mug_file, reset_contents)

        # Remove the temp file, don't need it now.
        os.remove("mug_files/temp.mug")

        print("")
        print("Changes saved to {}".format(mug_file))
        print("If you need to reset GAMBIT, do:")
        print("\t./gum -r {}".format(mug_file))

        # All done!
        print("")
        print("GUM has finished successfully!")
        # Prints the recommended build commands to stdout.
        write_config_file(output_opts, gum.name, reset_contents, rebuild_backends)

    except Exception as exc:
        print("\n\nGUM has failed!")
        if os.path.exists("mug_files/temp.mug"):
            print("Removing all added content...")
            blockPrint()                     # Stop the output for a sec
            revert("mug_files/temp.mug")     # Remove it all
            enablePrint()                    # Allow printing again
            os.remove("mug_files/temp.mug")  # Remove the temp mug file
            print("\nError message:\n")
        import traceback
        traceback.print_exc()

# Input option: .mug reset
elif args.reset:
    try:
        revert(args.reset)
        model = os.path.split(args.reset)[-1].strip('.mug')
        print("GUM has removed the model '{0}' from GAMBIT.".format(model))
    except Exception as exc:
        import traceback
        traceback.print_exc()

# No input options given
else:
    raise GumError(("\n\n\tHi! You must be new here (or you're just excited)!"
                    "\n\n\tUsage: gum -f inifile.gum"
                    "\n\n\tOr try gum -h for help.\n"))
